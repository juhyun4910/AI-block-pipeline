{% extends "base.html" %}
{% block title %}프로젝트 상세 설명{% endblock %}
{% block content %}
<section class="overview">
  <h1>🧱 Drag & Drop AI Pipeline Builder — One-Page Overview</h1>
  <p class="lead">
    문서 기반 RAG 파이프라인을 비전공자도 블록 조립처럼 구성 → 테스트 → 배포까지 끝낼 수 있도록 설계한
    서비스의 주요 기능과 백엔드 아키텍처를 정리했습니다.
  </p>

  <article>
    <h2>🔗 한 줄 요약</h2>
    <p>
      업로드 → 전처리 → 임베딩(단일) → 검색 → LLM → 가드레일 블록을 연결하고 Freeze로 스냅샷을 고정한 뒤,
      웹앱 · 위젯 · API 방식으로 동일한 파이프라인을 배포합니다. 원본은 MinIO에 저장하고, 색인은 Postgres(pgvector),
      모델은 Ollama/SBERT 컨테이너로 온디맨드 로딩·캐싱합니다.
    </p>
  </article>

  <article>
    <h2>1) 사용자 플로우 (Block Workflow)</h2>
    <table class="overview-table">
      <thead>
        <tr>
          <th>단계</th>
          <th>블록</th>
          <th>핵심 기능</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>📂 업로드 블록</td>
          <td>이름·설명·권한 설정 → Presigned URL 업로드 → SHA-256 중복 체크 → commit 시 인덱싱 시작</td>
        </tr>
        <tr>
          <td>2</td>
          <td>🔧 전처리 블록</td>
          <td>정규화 / 언어 감지·변환 / 표·코드 보존 / PII 마스킹 / 정규식 필터 / 청크 생성</td>
        </tr>
        <tr>
          <td>3</td>
          <td>🧠 임베딩 블록</td>
          <td>임베딩 모델 1개 고정 · 청크당 벡터 생성 · 모델 변경 시 재인덱싱</td>
        </tr>
        <tr>
          <td>4</td>
          <td>🔍 검색 블록</td>
          <td>top_k, 유사도 임계값, 중복 제거, 하이브리드(BM25+Vector), 메타 필터·리랭킹</td>
        </tr>
        <tr>
          <td>5</td>
          <td>✨ LLM 블록</td>
          <td>온도·토큰·출력 형식·스트리밍 / 모델 즉시 실행(캐싱)</td>
        </tr>
        <tr>
          <td>6</td>
          <td>🛡 가드레일 블록</td>
          <td>PII / 욕설 / 증오 / 불법 / 성인 / 자해 / 정책 기반 허용·마스킹·차단 / 감사 로그</td>
        </tr>
        <tr>
          <td>7</td>
          <td>🚀 테스트 → 배포</td>
          <td>샘플 질의 품질 확인 → Freeze → 공유 링크 / 위젯 / API 배포</td>
        </tr>
      </tbody>
    </table>
  </article>

  <article>
    <h2>2) 데이터 업로드 설계</h2>
    <p>Presigned URL을 사용해 대용량도 서버 부하 없이 처리하고, 원본과 메타데이터를 분리 저장합니다.</p>
    <pre class="code-block">Browser
 ├ (1) /uploads/check   → FastAPI (중복/권한 확인)
 ├ (2) /uploads/presign → FastAPI → MinIO (키 발급)
 ├ (3) PUT 파일         → MinIO (직접 전송, 서버 무부하)
 └ (4) /uploads/commit  → FastAPI → Postgres(file 레코드 확정)</pre>
    <ul>
      <li>✅ Presigned URL → 대용량도 서버 부하 없음</li>
      <li>✅ 원본: MinIO / 메타데이터: Postgres (업로더, 시각, 크기, MIME, SHA-256 등)</li>
    </ul>
  </article>

  <article>
    <h2>3) 전처리 흐름 (Summary)</h2>
    <ol>
      <li>텍스트 추출</li>
      <li>정규화(공백/개행/특수문자 정리)</li>
      <li>표·코드 보존 태깅</li>
      <li>언어 감지·변환</li>
      <li>PII 마스킹(이메일/전화/주민/주소)</li>
      <li>사용자 정의 필터(정규식)</li>
      <li>청크 → DB 저장 (전처리 원본은 저장 ❌)</li>
    </ol>
  </article>

  <article>
    <h2>4) 모델 선택 가이드</h2>
    <h3>🧠 임베딩 모델 (Search Indexing)</h3>
    <table class="overview-table">
      <thead>
        <tr>
          <th>차원</th>
          <th>모델</th>
          <th>특징</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td rowspan="5">384d (기본)</td>
          <td>all-MiniLM-L6-v2</td>
          <td>가볍고 빠름, 영어 강점</td>
        </tr>
        <tr>
          <td>e5-small / multilingual-e5-small</td>
          <td>표준, 다국어</td>
        </tr>
        <tr>
          <td>gte-small</td>
          <td>다국어, CPU 친화</td>
        </tr>
        <tr>
          <td>bge-small-en/zh</td>
          <td>경량</td>
        </tr>
        <tr>
          <td colspan="2">권장: 384d 기본 → 한글/다국어 비중 높다면 multilingual-e5-small 또는 gte-small</td>
        </tr>
        <tr>
          <td>768d (선택 옵션)</td>
          <td>nomic-embed-text</td>
          <td>품질↑, 저장비용↑</td>
        </tr>
      </tbody>
    </table>
    <h3>✨ LLM 모델 (Generation)</h3>
    <table class="overview-table">
      <thead>
        <tr>
          <th>모델</th>
          <th>용량</th>
          <th>비고</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Qwen2.5-Instruct</td>
          <td>1.5B / 3B</td>
          <td>양자화 가능</td>
        </tr>
        <tr>
          <td>Llama 3.2-Instruct</td>
          <td>1B / 3B</td>
          <td>경량 데모용</td>
        </tr>
        <tr>
          <td>Phi-3-mini</td>
          <td>3.8B</td>
          <td>CPU에서도 적합</td>
        </tr>
      </tbody>
    </table>
    <p>📌 실행 환경: Ollama (LLM + 일부 임베딩), SBERT 컨테이너(384d 임베딩) — 전부 독립 Docker 컨테이너로 온디맨드 로딩 및 사전 캐싱.</p>
  </article>

  <article>
    <h2>5) 운영 제약 (일관성 유지 목적)</h2>
    <table class="overview-table">
      <thead>
        <tr>
          <th>제약</th>
          <th>이유</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>데이터셋당 임베딩 모델 1개</td>
          <td>다중 벡터 인덱스 운영 복잡도 제거</td>
        </tr>
        <tr>
          <td>모델 교체 시 재인덱싱 필수</td>
          <td>벡터 차원/스페이스 불일치 방지</td>
        </tr>
        <tr>
          <td>기본 384d, 768d는 선택적</td>
          <td>저장 비용·메모리 경고 표시</td>
        </tr>
        <tr>
          <td>중복 인덱싱 금지</td>
          <td>해시 기반 식별 → 일관성 유지</td>
        </tr>
      </tbody>
    </table>
  </article>

  <article>
    <h2>6) 배포 (Freeze → Deploy)</h2>
    <h3>🧊 Freeze 시 자동 생성 파일</h3>
    <table class="overview-table">
      <thead>
        <tr>
          <th>파일</th>
          <th>역할</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>pipeline.json</code></td>
          <td>전처리/검색/프롬프트/가드레일 설정 스냅샷</td>
        </tr>
        <tr>
          <td><code>models.lock</code></td>
          <td>임베딩·LLM 버전/태그 고정</td>
        </tr>
        <tr>
          <td><code>dataset.ref</code></td>
          <td>데이터셋 ID, 차원, 완료 시각</td>
        </tr>
        <tr>
          <td><code>deploy.env.tpl</code></td>
          <td>MinIO / PG / Ollama 환경변수 템플릿</td>
        </tr>
      </tbody>
    </table>
    <p>UI 버튼 “배포 준비(Freeze)”를 누르면 위 리소스를 일괄 생성합니다.</p>
    <h3>🚀 배포 방식</h3>
    <ul>
      <li><strong>A. 공유 링크 웹앱</strong> — <code>/app/{pipeline_id}</code> (로그인/비공개/읽기전용 옵션)</li>
      <li><strong>B. 임베드 위젯</strong> — <code>&lt;iframe src="/widget/{pipeline_id}"&gt;</code> (테마/자동 높이/도메인 제한)</li>
      <li><strong>C. REST API</strong> — <code>POST /v1/pipelines/{id}:invoke</code> → <code>{question, session_id, metadata, stream?}</code></li>
    </ul>
    <p>응답은 <code>answer</code>, <code>citations[]</code>, <code>latency</code>, <code>tokens</code>를 포함하며 SSE 스트리밍을 지원합니다.</p>
  </article>

  <article>
    <h2>✅ 결론</h2>
    <p>
      Drag & Drop 방식으로 RAG 파이프라인을 구성하고 Freeze 스냅샷을 생성하면, 동일한 구성을 다양한 배포 채널에서 즉시 활용할 수 있습니다.
      MinIO + Postgres(pgvector) + Docker 모델 런타임(Ollama/SBERT)을 조합해 운영 복잡도를 줄이고, “드래그 후 즉시 사용” UX를 제공하는 것이 핵심입니다.
    </p>
  </article>
</section>
{% endblock %}
